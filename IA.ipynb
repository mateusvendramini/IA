{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0dfaf71",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "O objetivo deste trabalho é gerar um classificador knn para a base de dados [adult](http://mlr.cs.umass.edu/ml/datasets/Census+Income). Esta base de dados contém os dados do censo americado de 19xx e \n",
    "Para isto o primeiro passo é ler a base de dados e tratá-los para ser possível :\n",
    "* Ler a base de dados e tratar eventuais inconsistências\n",
    "* Remove colunas redudantes\n",
    "* Transformar as categorias em encoding numérico \n",
    "* Normalizar atributos numéricos para variarem no intervalo de 0 a 1\n",
    "\n",
    "### Importando bibliotecas e lendo base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d9d1a56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final_weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842</td>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>33906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22379</td>\n",
       "      <td>6172</td>\n",
       "      <td>19716</td>\n",
       "      <td>41762</td>\n",
       "      <td>32650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43832</td>\n",
       "      <td>24720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.643585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.896641e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1079.067626</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.422382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.056040e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7452.019058</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>12.391444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.175505e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.781445e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.376420e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age workclass  final_weight education  education_num  \\\n",
       "count   48842.000000     48842  4.884200e+04     48842   48842.000000   \n",
       "unique           NaN         9           NaN        16            NaN   \n",
       "top              NaN   Private           NaN   HS-grad            NaN   \n",
       "freq             NaN     33906           NaN     15784            NaN   \n",
       "mean       38.643585       NaN  1.896641e+05       NaN      10.078089   \n",
       "std        13.710510       NaN  1.056040e+05       NaN       2.570973   \n",
       "min        17.000000       NaN  1.228500e+04       NaN       1.000000   \n",
       "25%        28.000000       NaN  1.175505e+05       NaN       9.000000   \n",
       "50%        37.000000       NaN  1.781445e+05       NaN      10.000000   \n",
       "75%        48.000000       NaN  2.376420e+05       NaN      12.000000   \n",
       "max        90.000000       NaN  1.490400e+06       NaN      16.000000   \n",
       "\n",
       "            marital_status      occupation relationship   race    sex  \\\n",
       "count                48842           48842        48842  48842  48842   \n",
       "unique                   7              15            6      5      2   \n",
       "top     Married-civ-spouse  Prof-specialty      Husband  White   Male   \n",
       "freq                 22379            6172        19716  41762  32650   \n",
       "mean                   NaN             NaN          NaN    NaN    NaN   \n",
       "std                    NaN             NaN          NaN    NaN    NaN   \n",
       "min                    NaN             NaN          NaN    NaN    NaN   \n",
       "25%                    NaN             NaN          NaN    NaN    NaN   \n",
       "50%                    NaN             NaN          NaN    NaN    NaN   \n",
       "75%                    NaN             NaN          NaN    NaN    NaN   \n",
       "max                    NaN             NaN          NaN    NaN    NaN   \n",
       "\n",
       "        capital_gain  capital_loss  hours_per_week native_country income_class  \n",
       "count   48842.000000  48842.000000    48842.000000          48842        48842  \n",
       "unique           NaN           NaN             NaN             42            4  \n",
       "top              NaN           NaN             NaN  United-States        <=50K  \n",
       "freq             NaN           NaN             NaN          43832        24720  \n",
       "mean     1079.067626     87.502314       40.422382            NaN          NaN  \n",
       "std      7452.019058    403.004552       12.391444            NaN          NaN  \n",
       "min         0.000000      0.000000        1.000000            NaN          NaN  \n",
       "25%         0.000000      0.000000       40.000000            NaN          NaN  \n",
       "50%         0.000000      0.000000       40.000000            NaN          NaN  \n",
       "75%         0.000000      0.000000       45.000000            NaN          NaN  \n",
       "max     99999.000000   4356.000000       99.000000            NaN          NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "import numbers\n",
    "\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "CURRENT_DIR = os.path.abspath(os.path.dirname(__name__))\n",
    "DATA_DIR = os.path.join(CURRENT_DIR, 'data')\n",
    "\n",
    "TRAIN_DATA_FILE = os.path.join(DATA_DIR, 'adult.data')\n",
    "TEST_DATA_FILE = os.path.join(DATA_DIR, 'adult.test')\n",
    "\n",
    "from collections import OrderedDict\n",
    "#extracted from \n",
    "data_types = OrderedDict([\n",
    "    (\"age\", \"int\"),\n",
    "    (\"workclass\", \"category\"),\n",
    "    (\"final_weight\", \"int\"),  # originally it was called fnlwgt\n",
    "    (\"education\", \"category\"),\n",
    "    (\"education_num\", \"int\"),\n",
    "    (\"marital_status\", \"category\"),\n",
    "    (\"occupation\", \"category\"),\n",
    "    (\"relationship\", \"category\"),\n",
    "    (\"race\", \"category\"),\n",
    "    (\"sex\", \"category\"),\n",
    "    (\"capital_gain\", \"float\"),  # required because of NaN values\n",
    "    (\"capital_loss\", \"int\"),\n",
    "    (\"hours_per_week\", \"int\"),\n",
    "    (\"native_country\", \"category\"),\n",
    "    (\"income_class\", \"category\"),\n",
    "])\n",
    "target_column = \"income_class\"\n",
    "\n",
    "#reading data\n",
    "def read_dataset(path):\n",
    "    data = pd.read_csv(\n",
    "        path,\n",
    "        names=data_types,\n",
    "        index_col=None,\n",
    "        dtype=data_types,\n",
    "        comment='|',  \n",
    "        skipinitialspace=True\n",
    "    )\n",
    "    #data = data.drop('final_weight', axis=1)\n",
    "    return data\n",
    "\n",
    "train_data = read_dataset(TRAIN_DATA_FILE)\n",
    "test_data = read_dataset(TEST_DATA_FILE)\n",
    "\n",
    "#concatena teste a data para avaliar o pré processamento\n",
    "data = pd.concat([test_data, train_data])\n",
    "(data.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d3473",
   "metadata": {},
   "source": [
    "Nesta primeira importação vemos que a coluna 'final_weight' contem apenas informações sobre a coleta dos dados e não nos diz nada sobre a variável que queremos aprender.\n",
    "\n",
    "## Pré-processamento\n",
    "Nesta etapa vamos\n",
    "* Remover colunas redundante\n",
    "* Codificar categorias\n",
    "* Normalizar categorias\n",
    "* Lidar com dados faltantes\n",
    "\n",
    "### Remoção de inconsistências\n",
    "Vemos de cara que algumas classes estão com valores inconsistencias. Por exemplo a classe alvo 'income_class' tem 4 valores quando na verdade deveriam ter apenas 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db760eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income_class\n",
       "<=50K     24720\n",
       "<=50K.    12435\n",
       ">50K       7841\n",
       ">50K.      3846\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.income_class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2173d24e",
   "metadata": {},
   "source": [
    "Observando o value_counts vemos que isto se deve a um '.' adicional em uma das categorias.\n",
    "Deve ser limpado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02ebdc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income_class\n",
       "<=50K    37155\n",
       ">50K     11687\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['income_class'] = data.income_class.str.rstrip('.').astype('category')\n",
    "data.income_class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c431153",
   "metadata": {},
   "source": [
    "Também notamos que algumas categorias numéricas tem valores '9' de forma muito frequente o que pode indicar um placeholder para valores faltantes nestas categorias.\n",
    "Observando a frequência dos 5 valores mais comuns de 'capital_gain' e 'hours_per_week'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70578aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hours_per_week\n",
       "99    137\n",
       "98     14\n",
       "96      9\n",
       "97      2\n",
       "95      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "hours_per_week_counts = data.hours_per_week.value_counts()\n",
    "data.hours_per_week.value_counts()[hours_per_week_counts.index.isin(heapq.nlargest(5, data.hours_per_week.unique()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "51b8d604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "capital_gain\n",
       "99999.0    244\n",
       "27828.0     58\n",
       "25236.0     14\n",
       "34095.0      6\n",
       "41310.0      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "capital_gain_counts = data.capital_gain.value_counts()\n",
    "data.capital_gain.value_counts()[capital_gain_counts.index.isin(heapq.nlargest(5, data.capital_gain.unique()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1c7a2f",
   "metadata": {},
   "source": [
    "Como esperado vemos que estes valores estão muito mais frequentes que suas redondezas, indicando que devem ser removidos.\n",
    "Para isto vamos substituí-los pela média destas colunas já excluindo estes valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0a56177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_mean = np.mean(data.capital_gain[data.capital_gain != 99999])\n",
    "data['capital_gain'] = data['capital_gain'].replace(99999, capital_mean)\n",
    "hours_per_week_mean = np.mean(data.hours_per_week[data.hours_per_week != 99])\n",
    "data['hours_per_week'] = data['hours_per_week'].replace(99, hours_per_week_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e1a11",
   "metadata": {},
   "source": [
    "### Dados faltantes\n",
    "Observando os dados vemos que as colunas 'workclass', 'occuptation' e 'native_country' tem dados faltantes indicados por '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eadca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         2799\n",
       "final_weight         0\n",
       "education            0\n",
       "education_num        0\n",
       "marital_status       0\n",
       "occupation        2809\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital_gain         0\n",
       "capital_loss         0\n",
       "hours_per_week       0\n",
       "native_country     857\n",
       "income_class         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data == '?').sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8eae98",
   "metadata": {},
   "source": [
    "Nestas categorias vamos substituir os valores faltantes pelos mais frequentes nestas classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1145369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['workclass'] = data['workclass'].replace('?', 'Private')\n",
    "data['occupation'] = data['occupation'].replace('?', 'Prof-specialty')\n",
    "data['native_country'] = data['native_country'].replace('?', 'United-States')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732700a2",
   "metadata": {},
   "source": [
    "### Avaliação de Classes Correlacionadas\n",
    "\n",
    "Observando as colunas é imediato que algumas classes devem ter grande correlação entre si. Por exemplo: é de se esperar uma correlação grande entre 'relationship' e 'marital_status', 'education' e 'education_num'.\n",
    "Para garantir que não estamos introduzindo nenhum viés adicional a base de dados vamos avaliar a correlação entre estas colunas.\n",
    "Para avaliar a correlação entre duas categorias vamos utilizar a métrica 'Cramers V'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0da0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.4880589431633566)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# le = preprocessing.LabelEncoder()\n",
    "# marital_status = le.fit_transform(data.marital_status)\n",
    "# relationship = le.fit_transform(data.relationship)\n",
    "# stats.pointbiserialr(marital_status, relationship)\n",
    "def cramers_v(confusion_matrix):\n",
    "    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n",
    "        uses correction from Bergsma and Wicher,\n",
    "        Journal of the Korean Statistical Society 42 (2013): 323-328\n",
    "    \"\"\"\n",
    "    chi2 = stats.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum()\n",
    "    n = n.sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r - 1) ** 2) / (n - 1)\n",
    "    kcorr = k - ((k - 1) ** 2) / (n - 1)\n",
    "    return np.sqrt(phi2corr / min((kcorr - 1), (rcorr - 1)))\n",
    "\n",
    "confusion_matrix = pd.crosstab(data['marital_status'], data['relationship'])\n",
    "cramers_v(confusion_matrix=confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff65992a",
   "metadata": {},
   "source": [
    "Para comparação vamos ver a correlação entre 'marital_status' e 'occupation'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cf947d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.13056760739929651)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(data['marital_status'], data['occupation'])\n",
    "cramers_v(confusion_matrix=confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae92d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.3997244048209072)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(data['workclass'], data['occupation'])\n",
    "cramers_v(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1a583",
   "metadata": {},
   "source": [
    "Para avaliar a correlação entre 'education' e 'education_num' vamos utilizar a correlação biserial e utilizar uma serialização por LabelEncoder para  'education' apenas para verificar a correlação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eacf34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=np.float64(0.3596676843392162), pvalue=np.float64(0.0))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "# le = preprocessing.LabelEncoder()\n",
    "education = le.fit_transform(data.education)\n",
    "stats.pointbiserialr(education, data.education_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8cd92",
   "metadata": {},
   "source": [
    "Desta forma, vemos que há uma alta covariância entre as colunas:\n",
    "* education x education_num\n",
    "* marital_status x relationship\n",
    "* ocupation x workclass\n",
    "\n",
    "Para simplificar o modelo vamos escolher as colunas education_num (por já ser numérica e carregar a informação de \"mais anos estudados\"), relationship  e occupation (por conterém menos classes) ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e4870e",
   "metadata": {},
   "source": [
    "### Classes com elementos superrepresentados\n",
    "\n",
    "Vemos que na coluna 'native_country' 90% dos respondentes tem nacionalidade 'United-States' e além disso, temos 42 categorias diferentes para esta coluna.\n",
    "Por conta disso vamos trocar essa classe por: native-american com 1 indicando que é americano, 0 indicando que não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f40b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usa_map(i):\n",
    "    if i == 39:\n",
    "        return 1\n",
    "    return 0\n",
    "    \n",
    "data['native_country'] = data['native_country'].astype('category')\n",
    "data['native_usa'] = data['native_country'].cat.codes.map(usa_map)\n",
    "data = data.drop('native_country', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1489b22",
   "metadata": {},
   "source": [
    "Com isto podemos criar uma função para limpar todos os dados e mapear os valores inteiros entre 0 a 1 dividindo pelo máximo da coluna e utilizar HotEncoding para os valores categócios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "018ebef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final_weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842</td>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>33906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22379</td>\n",
       "      <td>6172</td>\n",
       "      <td>19716</td>\n",
       "      <td>41762</td>\n",
       "      <td>32650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43832</td>\n",
       "      <td>37155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.643585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.896641e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>582.412136</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.257612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.056040e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2530.307226</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>11.995659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.175505e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.781445e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.376420e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41310.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age workclass  final_weight education  education_num  \\\n",
       "count   48842.000000     48842  4.884200e+04     48842   48842.000000   \n",
       "unique           NaN         9           NaN        16            NaN   \n",
       "top              NaN   Private           NaN   HS-grad            NaN   \n",
       "freq             NaN     33906           NaN     15784            NaN   \n",
       "mean       38.643585       NaN  1.896641e+05       NaN      10.078089   \n",
       "std        13.710510       NaN  1.056040e+05       NaN       2.570973   \n",
       "min        17.000000       NaN  1.228500e+04       NaN       1.000000   \n",
       "25%        28.000000       NaN  1.175505e+05       NaN       9.000000   \n",
       "50%        37.000000       NaN  1.781445e+05       NaN      10.000000   \n",
       "75%        48.000000       NaN  2.376420e+05       NaN      12.000000   \n",
       "max        90.000000       NaN  1.490400e+06       NaN      16.000000   \n",
       "\n",
       "            marital_status      occupation relationship   race    sex  \\\n",
       "count                48842           48842        48842  48842  48842   \n",
       "unique                   7              15            6      5      2   \n",
       "top     Married-civ-spouse  Prof-specialty      Husband  White   Male   \n",
       "freq                 22379            6172        19716  41762  32650   \n",
       "mean                   NaN             NaN          NaN    NaN    NaN   \n",
       "std                    NaN             NaN          NaN    NaN    NaN   \n",
       "min                    NaN             NaN          NaN    NaN    NaN   \n",
       "25%                    NaN             NaN          NaN    NaN    NaN   \n",
       "50%                    NaN             NaN          NaN    NaN    NaN   \n",
       "75%                    NaN             NaN          NaN    NaN    NaN   \n",
       "max                    NaN             NaN          NaN    NaN    NaN   \n",
       "\n",
       "        capital_gain  capital_loss  hours_per_week native_country income_class  \n",
       "count   48842.000000  48842.000000    48842.000000          48842        48842  \n",
       "unique           NaN           NaN             NaN             42            2  \n",
       "top              NaN           NaN             NaN  United-States        <=50K  \n",
       "freq             NaN           NaN             NaN          43832        37155  \n",
       "mean      582.412136     87.502314       40.257612            NaN          NaN  \n",
       "std      2530.307226    403.004552       11.995659            NaN          NaN  \n",
       "min         0.000000      0.000000        1.000000            NaN          NaN  \n",
       "25%         0.000000      0.000000       40.000000            NaN          NaN  \n",
       "50%         0.000000      0.000000       40.000000            NaN          NaN  \n",
       "75%         0.000000      0.000000       45.000000            NaN          NaN  \n",
       "max     41310.000000   4356.000000       98.000000            NaN          NaN  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5ec73cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(data):\n",
    "    data = data.drop('final_weight', axis=1) # drops final_weight\n",
    "    data = data.drop('workclass', axis=1) # drops workclass\n",
    "    data = data.drop('education', axis=1) # drops education\n",
    "    data = data.drop('relationship', axis=1) #drops  relationship\n",
    "\n",
    "    data['income_class'] = data.income_class.str.rstrip('.').astype('category')\n",
    "\n",
    "    capital_mean = np.mean(data.capital_gain[data.capital_gain != 99999])\n",
    "    data['capital_gain'] = data['capital_gain'].replace(99999, capital_mean)\n",
    "    hours_per_week_mean = np.mean(data.hours_per_week[data.hours_per_week != 99])\n",
    "    data['hours_per_week'] = data['hours_per_week'].replace(99, hours_per_week_mean)\n",
    "\n",
    "    #data['workclass'] = data['workclass'].replace('?', 'Private')\n",
    "    data['occupation'] = data['occupation'].replace('?', 'Prof-specialty')\n",
    "\n",
    "    # condensa classe native_country\n",
    "    data['native_country'] = data['native_country'].replace('?', 'United-States')\n",
    "    data['native_country'] = data['native_country'].astype('category')\n",
    "    mode = data['native_country'].cat.codes.mode()\n",
    "    print(mode[0])\n",
    "    usa_map = lambda a : True if a == mode[0] else False\n",
    "\n",
    "    native_usa = data['native_country'].cat.codes.map(usa_map)\n",
    "    data = data.drop('native_country', axis=1)\n",
    "    data = pd.concat([data, native_usa], axis=1)\n",
    "\n",
    "    #normaliza valores numéricos\n",
    "    data['age'] = data['age']/90\n",
    "    data['education_num'] = data['education_num']/16\n",
    "    data['capital_gain'] = data['capital_gain']/41310.0\n",
    "    data['capital_loss'] = data['capital_loss']/4356.0\n",
    "    data['hours_per_week'] = data['hours_per_week']/98\n",
    "\n",
    "    # one hot enconding \n",
    "    marital_oh = pd.get_dummies(data['marital_status'])\n",
    "    data = data.drop('marital_status', axis=1)\n",
    "    data = pd.concat([data, marital_oh]).reset_index(drop=True)\n",
    "\n",
    "    occupation_oh = pd.get_dummies(data['occupation'])\n",
    "    data = data.drop('occupation', axis=1)\n",
    "    data = pd.concat([data, occupation_oh]).reset_index(drop=True)\n",
    "\n",
    "    race_oh = pd.get_dummies(data['race'])\n",
    "    data = data.drop('race', axis=1)\n",
    "    data = pd.concat([data, race_oh]).reset_index(drop=True)\n",
    "\n",
    "    sex_oh = pd.get_dummies(data['sex'])\n",
    "    data = data.drop('sex',axis=1)\n",
    "    data = pd.concat([data, sex_oh]).reset_index(drop=True)\n",
    "    #drop duplicates \n",
    "    data = data.drop_duplicates()\n",
    "\n",
    "    #saída \n",
    "    y = data['income_class']\n",
    "    data = data.drop('income_class', axis=1)\n",
    "    return data, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8571814a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MateusVendramini\\AppData\\Local\\Temp\\ipykernel_10264\\3120388230.py:15: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  data['occupation'] = data['occupation'].replace('?', 'Prof-specialty')\n",
      "C:\\Users\\MateusVendramini\\AppData\\Local\\Temp\\ipykernel_10264\\3120388230.py:18: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  data['native_country'] = data['native_country'].replace('?', 'United-States')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>0</th>\n",
       "      <th>Divorced</th>\n",
       "      <th>Married-AF-spouse</th>\n",
       "      <th>Married-civ-spouse</th>\n",
       "      <th>Married-spouse-absent</th>\n",
       "      <th>...</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Tech-support</th>\n",
       "      <th>Transport-moving</th>\n",
       "      <th>Amer-Indian-Eskimo</th>\n",
       "      <th>Asian-Pac-Islander</th>\n",
       "      <th>Black</th>\n",
       "      <th>Other</th>\n",
       "      <th>White</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8041.000000</td>\n",
       "      <td>8041.000000</td>\n",
       "      <td>8041.000000</td>\n",
       "      <td>8041.000000</td>\n",
       "      <td>8041.000000</td>\n",
       "      <td>8041</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6997</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.468770</td>\n",
       "      <td>0.635516</td>\n",
       "      <td>0.026702</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.415763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.162771</td>\n",
       "      <td>0.189096</td>\n",
       "      <td>0.082167</td>\n",
       "      <td>0.127262</td>\n",
       "      <td>0.152409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  education_num  capital_gain  capital_loss  \\\n",
       "count   8041.000000    8041.000000   8041.000000   8041.000000   \n",
       "unique          NaN            NaN           NaN           NaN   \n",
       "top             NaN            NaN           NaN           NaN   \n",
       "freq            NaN            NaN           NaN           NaN   \n",
       "mean       0.468770       0.635516      0.026702      0.040003   \n",
       "std        0.162771       0.189096      0.082167      0.127262   \n",
       "min        0.188889       0.062500      0.000000      0.000000   \n",
       "25%        0.344444       0.562500      0.000000      0.000000   \n",
       "50%        0.455556       0.625000      0.000000      0.000000   \n",
       "75%        0.577778       0.812500      0.000000      0.000000   \n",
       "max        1.000000       1.000000      1.000000      0.865473   \n",
       "\n",
       "        hours_per_week     0 Divorced Married-AF-spouse Married-civ-spouse  \\\n",
       "count      8041.000000  8041        7                 7                  7   \n",
       "unique             NaN     2        2                 2                  2   \n",
       "top                NaN  True    False             False              False   \n",
       "freq               NaN  6997        6                 6                  6   \n",
       "mean          0.415763   NaN      NaN               NaN                NaN   \n",
       "std           0.152409   NaN      NaN               NaN                NaN   \n",
       "min           0.010204   NaN      NaN               NaN                NaN   \n",
       "25%           0.357143   NaN      NaN               NaN                NaN   \n",
       "50%           0.408163   NaN      NaN               NaN                NaN   \n",
       "75%           0.510204   NaN      NaN               NaN                NaN   \n",
       "max           1.000000   NaN      NaN               NaN                NaN   \n",
       "\n",
       "       Married-spouse-absent  ...  Sales Tech-support Transport-moving  \\\n",
       "count                      7  ...     15           15               15   \n",
       "unique                     2  ...      2            2                2   \n",
       "top                    False  ...  False        False            False   \n",
       "freq                       6  ...     14           14               14   \n",
       "mean                     NaN  ...    NaN          NaN              NaN   \n",
       "std                      NaN  ...    NaN          NaN              NaN   \n",
       "min                      NaN  ...    NaN          NaN              NaN   \n",
       "25%                      NaN  ...    NaN          NaN              NaN   \n",
       "50%                      NaN  ...    NaN          NaN              NaN   \n",
       "75%                      NaN  ...    NaN          NaN              NaN   \n",
       "max                      NaN  ...    NaN          NaN              NaN   \n",
       "\n",
       "       Amer-Indian-Eskimo Asian-Pac-Islander  Black  Other  White Female  \\\n",
       "count                   6                  6      6      6      6      3   \n",
       "unique                  2                  2      2      2      2      2   \n",
       "top                 False              False  False  False  False  False   \n",
       "freq                    5                  5      5      5      5      2   \n",
       "mean                  NaN                NaN    NaN    NaN    NaN    NaN   \n",
       "std                   NaN                NaN    NaN    NaN    NaN    NaN   \n",
       "min                   NaN                NaN    NaN    NaN    NaN    NaN   \n",
       "25%                   NaN                NaN    NaN    NaN    NaN    NaN   \n",
       "50%                   NaN                NaN    NaN    NaN    NaN    NaN   \n",
       "75%                   NaN                NaN    NaN    NaN    NaN    NaN   \n",
       "max                   NaN                NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         Male  \n",
       "count       3  \n",
       "unique      2  \n",
       "top     False  \n",
       "freq        2  \n",
       "mean      NaN  \n",
       "std       NaN  \n",
       "min       NaN  \n",
       "25%       NaN  \n",
       "50%       NaN  \n",
       "75%       NaN  \n",
       "max       NaN  \n",
       "\n",
       "[11 rows x 34 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test, clean_output = clean_dataset(test_data)\n",
    "clean_test.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8bac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train, train_output = clean_dataset(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
