{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0dfaf71",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "O objetivo deste trabalho é gerar um classificador knn para a base de dados [adult](http://mlr.cs.umass.edu/ml/datasets/Census+Income). Esta base de dados contém os dados do censo americado de 19xx e \n",
    "Para isto o primeiro passo é ler a base de dados e tratá-los para ser possível :\n",
    "* Ler a base de dados e tratar eventuais inconsistências\n",
    "* Remove colunas redudantes\n",
    "* Transformar as categorias em encoding numérico \n",
    "* Normalizar atributos numéricos para variarem no intervalo de 0 a 1\n",
    "\n",
    "### Importando bibliotecas e lendo base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d9d1a56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final_weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842</td>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>33906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22379</td>\n",
       "      <td>6172</td>\n",
       "      <td>19716</td>\n",
       "      <td>41762</td>\n",
       "      <td>32650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43832</td>\n",
       "      <td>24720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.643585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.896641e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1079.067626</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.422382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.056040e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7452.019058</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>12.391444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.175505e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.781445e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.376420e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age workclass  final_weight education  education_num  \\\n",
       "count   48842.000000     48842  4.884200e+04     48842   48842.000000   \n",
       "unique           NaN         9           NaN        16            NaN   \n",
       "top              NaN   Private           NaN   HS-grad            NaN   \n",
       "freq             NaN     33906           NaN     15784            NaN   \n",
       "mean       38.643585       NaN  1.896641e+05       NaN      10.078089   \n",
       "std        13.710510       NaN  1.056040e+05       NaN       2.570973   \n",
       "min        17.000000       NaN  1.228500e+04       NaN       1.000000   \n",
       "25%        28.000000       NaN  1.175505e+05       NaN       9.000000   \n",
       "50%        37.000000       NaN  1.781445e+05       NaN      10.000000   \n",
       "75%        48.000000       NaN  2.376420e+05       NaN      12.000000   \n",
       "max        90.000000       NaN  1.490400e+06       NaN      16.000000   \n",
       "\n",
       "            marital_status      occupation relationship   race    sex  \\\n",
       "count                48842           48842        48842  48842  48842   \n",
       "unique                   7              15            6      5      2   \n",
       "top     Married-civ-spouse  Prof-specialty      Husband  White   Male   \n",
       "freq                 22379            6172        19716  41762  32650   \n",
       "mean                   NaN             NaN          NaN    NaN    NaN   \n",
       "std                    NaN             NaN          NaN    NaN    NaN   \n",
       "min                    NaN             NaN          NaN    NaN    NaN   \n",
       "25%                    NaN             NaN          NaN    NaN    NaN   \n",
       "50%                    NaN             NaN          NaN    NaN    NaN   \n",
       "75%                    NaN             NaN          NaN    NaN    NaN   \n",
       "max                    NaN             NaN          NaN    NaN    NaN   \n",
       "\n",
       "        capital_gain  capital_loss  hours_per_week native_country income_class  \n",
       "count   48842.000000  48842.000000    48842.000000          48842        48842  \n",
       "unique           NaN           NaN             NaN             42            4  \n",
       "top              NaN           NaN             NaN  United-States        <=50K  \n",
       "freq             NaN           NaN             NaN          43832        24720  \n",
       "mean     1079.067626     87.502314       40.422382            NaN          NaN  \n",
       "std      7452.019058    403.004552       12.391444            NaN          NaN  \n",
       "min         0.000000      0.000000        1.000000            NaN          NaN  \n",
       "25%         0.000000      0.000000       40.000000            NaN          NaN  \n",
       "50%         0.000000      0.000000       40.000000            NaN          NaN  \n",
       "75%         0.000000      0.000000       45.000000            NaN          NaN  \n",
       "max     99999.000000   4356.000000       99.000000            NaN          NaN  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "import numbers\n",
    "\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "CURRENT_DIR = os.path.abspath(os.path.dirname(__name__))\n",
    "DATA_DIR = os.path.join(CURRENT_DIR, 'data')\n",
    "\n",
    "TRAIN_DATA_FILE = os.path.join(DATA_DIR, 'adult.data')\n",
    "TEST_DATA_FILE = os.path.join(DATA_DIR, 'adult.test')\n",
    "\n",
    "from collections import OrderedDict\n",
    "#extracted from \n",
    "data_types = OrderedDict([\n",
    "    (\"age\", \"int\"),\n",
    "    (\"workclass\", \"category\"),\n",
    "    (\"final_weight\", \"int\"),  # originally it was called fnlwgt\n",
    "    (\"education\", \"category\"),\n",
    "    (\"education_num\", \"int\"),\n",
    "    (\"marital_status\", \"category\"),\n",
    "    (\"occupation\", \"category\"),\n",
    "    (\"relationship\", \"category\"),\n",
    "    (\"race\", \"category\"),\n",
    "    (\"sex\", \"category\"),\n",
    "    (\"capital_gain\", \"float\"),  # required because of NaN values\n",
    "    (\"capital_loss\", \"int\"),\n",
    "    (\"hours_per_week\", \"int\"),\n",
    "    (\"native_country\", \"category\"),\n",
    "    (\"income_class\", \"category\"),\n",
    "])\n",
    "target_column = \"income_class\"\n",
    "\n",
    "#reading data\n",
    "def read_dataset(path):\n",
    "    data = pd.read_csv(\n",
    "        path,\n",
    "        names=data_types,\n",
    "        index_col=None,\n",
    "        dtype=data_types,\n",
    "        comment='|',  \n",
    "        skipinitialspace=True\n",
    "    )\n",
    "    #data = data.drop('final_weight', axis=1)\n",
    "    return data\n",
    "\n",
    "train_data = read_dataset(TRAIN_DATA_FILE)\n",
    "test_data = read_dataset(TEST_DATA_FILE)\n",
    "\n",
    "#concatena teste a data para avaliar o pré processamento\n",
    "data = pd.concat([test_data, train_data])\n",
    "(data.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d3473",
   "metadata": {},
   "source": [
    "Nesta primeira importação vemos que a coluna 'final_weight' contem apenas informações sobre a coleta dos dados e não nos diz nada sobre a variável que queremos aprender.\n",
    "\n",
    "## Pré-processamento\n",
    "Nesta etapa vamos\n",
    "* Remover colunas redundante\n",
    "* Codificar categorias\n",
    "* Normalizar categorias\n",
    "* Lidar com dados faltantes\n",
    "\n",
    "### Remoção de inconsistências\n",
    "Vemos de cara que algumas classes estão com valores inconsistencias. Por exemplo a classe alvo 'income_class' tem 4 valores quando na verdade deveriam ter apenas 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "db760eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income_class\n",
       "<=50K     24720\n",
       "<=50K.    12435\n",
       ">50K       7841\n",
       ">50K.      3846\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.income_class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2173d24e",
   "metadata": {},
   "source": [
    "Observando o value_counts vemos que isto se deve a um '.' adicional em uma das categorias.\n",
    "Deve ser limpado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "02ebdc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income_class\n",
       "<=50K    37155\n",
       ">50K     11687\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['income_class'] = data.income_class.str.rstrip('.').astype('category')\n",
    "data.income_class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c431153",
   "metadata": {},
   "source": [
    "Também notamos que algumas categorias numéricas tem valores '9' de forma muito frequente o que pode indicar um placeholder para valores faltantes nestas categorias.\n",
    "Observando a frequência dos 5 valores mais comuns de 'capital_gain' e 'hours_per_week'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "70578aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hours_per_week\n",
       "99    137\n",
       "98     14\n",
       "96      9\n",
       "97      2\n",
       "95      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "hours_per_week_counts = data.hours_per_week.value_counts()\n",
    "data.hours_per_week.value_counts()[hours_per_week_counts.index.isin(heapq.nlargest(5, data.hours_per_week.unique()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "51b8d604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "capital_gain\n",
       "99999.0    244\n",
       "27828.0     58\n",
       "25236.0     14\n",
       "34095.0      6\n",
       "41310.0      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "capital_gain_counts = data.capital_gain.value_counts()\n",
    "data.capital_gain.value_counts()[capital_gain_counts.index.isin(heapq.nlargest(5, data.capital_gain.unique()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1c7a2f",
   "metadata": {},
   "source": [
    "Como esperado vemos que estes valores estão muito mais frequentes que suas redondezas, indicando que devem ser removidos.\n",
    "Para isto vamos substituí-los pela média destas colunas já excluindo estes valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0a56177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_mean = np.mean(data.capital_gain[data.capital_gain != 99999])\n",
    "data['capital_gain'] = data['capital_gain'].replace(99999, capital_mean)\n",
    "hours_per_week_mean = np.mean(data.hours_per_week[data.hours_per_week != 99])\n",
    "data['hours_per_week'] = data['hours_per_week'].replace(99, hours_per_week_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e1a11",
   "metadata": {},
   "source": [
    "### Dados faltantes\n",
    "Observando os dados vemos que as colunas 'workclass', 'occuptation' e 'native_country' tem dados faltantes indicados por '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "42eadca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         2799\n",
       "final_weight         0\n",
       "education            0\n",
       "education_num        0\n",
       "marital_status       0\n",
       "occupation        2809\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital_gain         0\n",
       "capital_loss         0\n",
       "hours_per_week       0\n",
       "native_country     857\n",
       "income_class         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data == '?').sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8eae98",
   "metadata": {},
   "source": [
    "Nestas categorias vamos substituir os valores faltantes pelos mais frequentes nestas classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1145369f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MateusVendramini\\AppData\\Local\\Temp\\ipykernel_10264\\4051293994.py:1: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  data['workclass'] = data['workclass'].replace('?', 'Private')\n",
      "C:\\Users\\MateusVendramini\\AppData\\Local\\Temp\\ipykernel_10264\\4051293994.py:2: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  data['occupation'] = data['occupation'].replace('?', 'Prof-specialty')\n"
     ]
    }
   ],
   "source": [
    "data['workclass'] = data['workclass'].replace('?', 'Private')\n",
    "data['occupation'] = data['occupation'].replace('?', 'Prof-specialty')\n",
    "data['native_country'] = data['native_country'].replace('?', 'United-States')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732700a2",
   "metadata": {},
   "source": [
    "### Avaliação de Classes Correlacionadas\n",
    "\n",
    "Observando as colunas é imediato que algumas classes devem ter grande correlação entre si. Por exemplo: é de se esperar uma correlação grande entre 'relationship' e 'marital_status', 'education' e 'education_num'.\n",
    "Para garantir que não estamos introduzindo nenhum viés adicional a base de dados vamos avaliar a correlação entre estas colunas.\n",
    "Para avaliar a correlação entre duas categorias vamos utilizar a métrica 'Cramers V'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4a0da0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.4880589431633566)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# le = preprocessing.LabelEncoder()\n",
    "# marital_status = le.fit_transform(data.marital_status)\n",
    "# relationship = le.fit_transform(data.relationship)\n",
    "# stats.pointbiserialr(marital_status, relationship)\n",
    "def cramers_v(confusion_matrix):\n",
    "    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n",
    "        uses correction from Bergsma and Wicher,\n",
    "        Journal of the Korean Statistical Society 42 (2013): 323-328\n",
    "    \"\"\"\n",
    "    chi2 = stats.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum()\n",
    "    n = n.sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r - 1) ** 2) / (n - 1)\n",
    "    kcorr = k - ((k - 1) ** 2) / (n - 1)\n",
    "    return np.sqrt(phi2corr / min((kcorr - 1), (rcorr - 1)))\n",
    "\n",
    "confusion_matrix = pd.crosstab(data['marital_status'], data['relationship'])\n",
    "cramers_v(confusion_matrix=confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff65992a",
   "metadata": {},
   "source": [
    "Para comparação vamos ver a correlação entre 'marital_status' e 'occupation'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a3cf947d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.12395188062684377)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(data['marital_status'], data['occupation'])\n",
    "cramers_v(confusion_matrix=confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "dae92d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.18911202171141478)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(data['workclass'], data['occupation'])\n",
    "cramers_v(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1a583",
   "metadata": {},
   "source": [
    "Para avaliar a correlação entre 'education' e 'education_num' vamos utilizar a correlação biserial e utilizar uma serialização por LabelEncoder para  'education' apenas para verificar a correlação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9eacf34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=np.float64(0.3596676843392162), pvalue=np.float64(0.0))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "# le = preprocessing.LabelEncoder()\n",
    "education = le.fit_transform(data.education)\n",
    "stats.pointbiserialr(education, data.education_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8cd92",
   "metadata": {},
   "source": [
    "Desta forma, vemos que há uma alta covariância entre as colunas:\n",
    "* education x education_num\n",
    "* marital_status x relationship\n",
    "* ocupation x workclass\n",
    "\n",
    "Para simplificar o modelo vamos escolher as colunas education_num (por já ser numérica e carregar a informação de \"mais anos estudados\"), relationship  e occupation (por conterém menos classes) ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e4870e",
   "metadata": {},
   "source": [
    "### Classes com elementos superrepresentados\n",
    "\n",
    "Vemos que na coluna 'native_country' 90% dos respondentes tem nacionalidade 'United-States' e além disso, temos 42 categorias diferentes para esta coluna.\n",
    "Por conta disso vamos trocar essa classe por: native-american com 1 indicando que é americano, 0 indicando que não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9f40b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['native_country'] = data['native_country'].astype('category')\n",
    "mode = data['native_country'].cat.codes.mode()\n",
    "usa_map = lambda a : True if a == mode[0] else False\n",
    "native_usa = data['native_country'].cat.codes.map(usa_map)\n",
    "data = data.drop('native_country', axis=1)\n",
    "native_usa_df = pd.DataFrame(data={'native_usa': native_usa})\n",
    "data = pd.concat([data, native_usa_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1489b22",
   "metadata": {},
   "source": [
    "Com isto podemos criar uma função para limpar todos os dados e mapear os valores inteiros entre 0 a 1 dividindo pelo máximo da coluna e utilizar HotEncoding para os valores categócios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "018ebef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final_weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income_class</th>\n",
       "      <th>native_usa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842</td>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>36705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22379</td>\n",
       "      <td>8981</td>\n",
       "      <td>19716</td>\n",
       "      <td>41762</td>\n",
       "      <td>32650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37155</td>\n",
       "      <td>44689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.643585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.896641e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>582.412136</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.257612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.056040e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2530.307226</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>11.995659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.175505e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.781445e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.376420e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41310.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age workclass  final_weight education  education_num  \\\n",
       "count   48842.000000     48842  4.884200e+04     48842   48842.000000   \n",
       "unique           NaN         8           NaN        16            NaN   \n",
       "top              NaN   Private           NaN   HS-grad            NaN   \n",
       "freq             NaN     36705           NaN     15784            NaN   \n",
       "mean       38.643585       NaN  1.896641e+05       NaN      10.078089   \n",
       "std        13.710510       NaN  1.056040e+05       NaN       2.570973   \n",
       "min        17.000000       NaN  1.228500e+04       NaN       1.000000   \n",
       "25%        28.000000       NaN  1.175505e+05       NaN       9.000000   \n",
       "50%        37.000000       NaN  1.781445e+05       NaN      10.000000   \n",
       "75%        48.000000       NaN  2.376420e+05       NaN      12.000000   \n",
       "max        90.000000       NaN  1.490400e+06       NaN      16.000000   \n",
       "\n",
       "            marital_status      occupation relationship   race    sex  \\\n",
       "count                48842           48842        48842  48842  48842   \n",
       "unique                   7              14            6      5      2   \n",
       "top     Married-civ-spouse  Prof-specialty      Husband  White   Male   \n",
       "freq                 22379            8981        19716  41762  32650   \n",
       "mean                   NaN             NaN          NaN    NaN    NaN   \n",
       "std                    NaN             NaN          NaN    NaN    NaN   \n",
       "min                    NaN             NaN          NaN    NaN    NaN   \n",
       "25%                    NaN             NaN          NaN    NaN    NaN   \n",
       "50%                    NaN             NaN          NaN    NaN    NaN   \n",
       "75%                    NaN             NaN          NaN    NaN    NaN   \n",
       "max                    NaN             NaN          NaN    NaN    NaN   \n",
       "\n",
       "        capital_gain  capital_loss  hours_per_week income_class native_usa  \n",
       "count   48842.000000  48842.000000    48842.000000        48842      48842  \n",
       "unique           NaN           NaN             NaN            2          2  \n",
       "top              NaN           NaN             NaN        <=50K       True  \n",
       "freq             NaN           NaN             NaN        37155      44689  \n",
       "mean      582.412136     87.502314       40.257612          NaN        NaN  \n",
       "std      2530.307226    403.004552       11.995659          NaN        NaN  \n",
       "min         0.000000      0.000000        1.000000          NaN        NaN  \n",
       "25%         0.000000      0.000000       40.000000          NaN        NaN  \n",
       "50%         0.000000      0.000000       40.000000          NaN        NaN  \n",
       "75%         0.000000      0.000000       45.000000          NaN        NaN  \n",
       "max     41310.000000   4356.000000       98.000000          NaN        NaN  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7c5cb5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final_weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>...</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income_class</th>\n",
       "      <th>native_usa</th>\n",
       "      <th>Divorced</th>\n",
       "      <th>Married-AF-spouse</th>\n",
       "      <th>Married-civ-spouse</th>\n",
       "      <th>Married-spouse-absent</th>\n",
       "      <th>Never-married</th>\n",
       "      <th>Separated</th>\n",
       "      <th>Widowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>Private</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  final_weight     education  education_num  \\\n",
       "0   25    Private        226802          11th              7   \n",
       "1   38    Private         89814       HS-grad              9   \n",
       "2   28  Local-gov        336951    Assoc-acdm             12   \n",
       "3   44    Private        160323  Some-college             10   \n",
       "4   18    Private        103497  Some-college             10   \n",
       "\n",
       "          occupation relationship   race     sex  capital_gain  ...  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male           0.0  ...   \n",
       "1    Farming-fishing      Husband  White    Male           0.0  ...   \n",
       "2    Protective-serv      Husband  White    Male           0.0  ...   \n",
       "3  Machine-op-inspct      Husband  Black    Male        7688.0  ...   \n",
       "4     Prof-specialty    Own-child  White  Female           0.0  ...   \n",
       "\n",
       "   hours_per_week  income_class native_usa  Divorced  Married-AF-spouse  \\\n",
       "0            40.0         <=50K       True     False              False   \n",
       "1            50.0         <=50K       True     False              False   \n",
       "2            40.0          >50K       True     False              False   \n",
       "3            40.0          >50K       True     False              False   \n",
       "4            30.0         <=50K       True     False              False   \n",
       "\n",
       "   Married-civ-spouse  Married-spouse-absent  Never-married  Separated  \\\n",
       "0               False                  False           True      False   \n",
       "1                True                  False          False      False   \n",
       "2                True                  False          False      False   \n",
       "3                True                  False          False      False   \n",
       "4               False                  False           True      False   \n",
       "\n",
       "   Widowed  \n",
       "0    False  \n",
       "1    False  \n",
       "2    False  \n",
       "3    False  \n",
       "4    False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exemplo de one hot encoding\n",
    "marital_oh = pd.get_dummies(data['marital_status'], dummy_na=False)\n",
    "data = data.drop('marital_status', axis=1)\n",
    "data = pd.concat([data, marital_oh], axis=1)\n",
    "data.head(5)\n",
    "#data = data.join(marital_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec73cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(data):\n",
    "    data = data.drop('final_weight', axis=1) # drops final_weight\n",
    "    data = data.drop('workclass', axis=1) # drops workclass\n",
    "    data = data.drop('education', axis=1) # drops education\n",
    "    data = data.drop('relationship', axis=1) #drops  relationship\n",
    "\n",
    "    data['income_class'] = data.income_class.str.rstrip('.').astype('category')\n",
    "\n",
    "    capital_mean = np.mean(data.capital_gain[data.capital_gain != 99999])\n",
    "    data['capital_gain'] = data['capital_gain'].replace(99999, capital_mean)\n",
    "    hours_per_week_mean = np.mean(data.hours_per_week[data.hours_per_week != 99])\n",
    "    data['hours_per_week'] = data['hours_per_week'].replace(99, hours_per_week_mean)\n",
    "\n",
    "    #data['workclass'] = data['workclass'].replace('?', 'Private')\n",
    "    data['occupation'] = data['occupation'].replace('?', 'Prof-specialty')\n",
    "\n",
    "    # condensa classe native_country\n",
    "    data['native_country'] = data['native_country'].replace('?', 'United-States')\n",
    "    data['native_country'] = data['native_country'].astype('category')\n",
    "    mode = data['native_country'].cat.codes.mode()\n",
    "    usa_map = lambda a : True if a == mode[0] else False\n",
    "\n",
    "    native_usa = data['native_country'].cat.codes.map(usa_map)\n",
    "    data = data.drop('native_country', axis=1)\n",
    "    data = pd.concat([data, native_usa], axis=1)\n",
    "\n",
    "    data['marital_status'] = data['marital_status'].replace('?', 'Married-civ-spouse')\n",
    "    #normaliza valores numéricos\n",
    "    data['age'] = data['age']/90\n",
    "    data['education_num'] = data['education_num']/16\n",
    "    data['capital_gain'] = data['capital_gain']/41310.0\n",
    "    data['capital_loss'] = data['capital_loss']/4356.0\n",
    "    data['hours_per_week'] = data['hours_per_week']/98\n",
    "\n",
    "    # one hot enconding \n",
    "    marital_oh = pd.get_dummies(data['marital_status'])\n",
    "    data = data.drop('marital_status', axis=1)\n",
    "    data = pd.concat([data, marital_oh], axis=1)\n",
    "\n",
    "    occupation_oh = pd.get_dummies(data['occupation'])\n",
    "    data = data.drop('occupation', axis=1)\n",
    "    data = pd.concat([data, occupation_oh], axis=1)\n",
    "\n",
    "    race_oh = pd.get_dummies(data['race'])\n",
    "    data = data.drop('race', axis=1)\n",
    "    data = pd.concat([data, race_oh], axis=1)\n",
    "\n",
    "    sex_oh = pd.get_dummies(data['sex'])\n",
    "    data = data.drop('sex',axis=1)\n",
    "    data = pd.concat([data, sex_oh], axis=1)\n",
    "    #drop duplicates \n",
    "    data = data.drop_duplicates()\n",
    "\n",
    "    #saída \n",
    "    y = data['income_class']\n",
    "    data = data.drop('income_class', axis=1)\n",
    "    return data, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8571814a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MateusVendramini\\AppData\\Local\\Temp\\ipykernel_10264\\1870677188.py:15: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  data['occupation'] = data['occupation'].replace('?', 'Prof-specialty')\n",
      "C:\\Users\\MateusVendramini\\AppData\\Local\\Temp\\ipykernel_10264\\1870677188.py:18: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  data['native_country'] = data['native_country'].replace('?', 'United-States')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>0</th>\n",
       "      <th>Divorced</th>\n",
       "      <th>Married-AF-spouse</th>\n",
       "      <th>Married-civ-spouse</th>\n",
       "      <th>Married-spouse-absent</th>\n",
       "      <th>...</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Tech-support</th>\n",
       "      <th>Transport-moving</th>\n",
       "      <th>Amer-Indian-Eskimo</th>\n",
       "      <th>Asian-Pac-Islander</th>\n",
       "      <th>Black</th>\n",
       "      <th>Other</th>\n",
       "      <th>White</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.186105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  education_num  capital_gain  capital_loss  hours_per_week     0  \\\n",
       "0  0.277778         0.4375      0.000000           0.0        0.408163  True   \n",
       "1  0.422222         0.5625      0.000000           0.0        0.510204  True   \n",
       "2  0.311111         0.7500      0.000000           0.0        0.408163  True   \n",
       "3  0.488889         0.6250      0.186105           0.0        0.408163  True   \n",
       "4  0.200000         0.6250      0.000000           0.0        0.306122  True   \n",
       "\n",
       "  Divorced Married-AF-spouse Married-civ-spouse Married-spouse-absent  ...  \\\n",
       "0      NaN               NaN                NaN                   NaN  ...   \n",
       "1      NaN               NaN                NaN                   NaN  ...   \n",
       "2      NaN               NaN                NaN                   NaN  ...   \n",
       "3      NaN               NaN                NaN                   NaN  ...   \n",
       "4      NaN               NaN                NaN                   NaN  ...   \n",
       "\n",
       "  Sales Tech-support Transport-moving Amer-Indian-Eskimo Asian-Pac-Islander  \\\n",
       "0   NaN          NaN              NaN                NaN                NaN   \n",
       "1   NaN          NaN              NaN                NaN                NaN   \n",
       "2   NaN          NaN              NaN                NaN                NaN   \n",
       "3   NaN          NaN              NaN                NaN                NaN   \n",
       "4   NaN          NaN              NaN                NaN                NaN   \n",
       "\n",
       "  Black Other White Female Male  \n",
       "0   NaN   NaN   NaN    NaN  NaN  \n",
       "1   NaN   NaN   NaN    NaN  NaN  \n",
       "2   NaN   NaN   NaN    NaN  NaN  \n",
       "3   NaN   NaN   NaN    NaN  NaN  \n",
       "4   NaN   NaN   NaN    NaN  NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test, clean_output = clean_dataset(test_data)\n",
    "#clean_test.describe(include='all')\n",
    "clean_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5e8bac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MateusVendramini\\AppData\\Local\\Temp\\ipykernel_10264\\3120388230.py:15: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  data['occupation'] = data['occupation'].replace('?', 'Prof-specialty')\n",
      "C:\\Users\\MateusVendramini\\AppData\\Local\\Temp\\ipykernel_10264\\3120388230.py:18: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  data['native_country'] = data['native_country'].replace('?', 'United-States')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "clean_train, train_output = clean_dataset(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2ca159",
   "metadata": {},
   "source": [
    "## Construção do kNN\n",
    "Para construir o classificador kNN precisamos definir o hiperparametro n.\n",
    "Para isso vamos utilizar o método k-fold cross validation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
